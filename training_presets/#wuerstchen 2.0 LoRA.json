{
    "backup_after": 10,
    "base_model_name": "warp-ai/wuerstchen-prior",
    "decoder_model_name": "warp-ai/wuerstchen",
    "effnet_encoder_model_name": "warp-ai/EfficientNetEncoder",
    "learning_rate": 0.0003,
    "model_type": "WUERSTCHEN_2",
    "output_model_destination": "models/lora.safetensors",
    "output_model_format": "SAFETENSORS",
    "resolution": "1024",
    "train_text_encoder_epochs": 30,
    "train_unet_epochs": 100000,
    "training_method": "LORA",
    "weight_dtype": "FLOAT_16"
}